<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Guide to deploy Ray Cluster on GKE | Quan H. Nguyen </title> <meta name="author" content="Quan H. Nguyen"> <meta name="description" content="A step-by-step production guide for Ray Cluster deployment distributed ML and LLM workloads"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?v=6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/favicon/bugcat.png?v=485c615ab95843a391ebd4d3c6dbb954"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://quanhnguyen232.github.io/blog/2026/deploy-ray/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.distillpost .post.distill{display:block!important}.distillpost d-title,.distillpost d-byline,.distillpost d-article,.distillpost d-appendix{display:block!important;grid-column:unset!important}.distillpost d-article>*{grid-column:unset!important}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Guide to deploy Ray Cluster on GKE",
            "description": "A step-by-step production guide for Ray Cluster deployment distributed ML and LLM workloads",
            "published": "February 28, 2026",
            "authors": [
              
              {
                "author": "Quan Nguyen",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Venera AI",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Quan</span> H. Nguyen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Academics </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/teaching/">teaching</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/people/">people</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Hobbies </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/photos/">photos</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5 distillpost" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post distill"> <d-title> <h1>Guide to deploy Ray Cluster on GKE</h1> <p>A step-by-step production guide for Ray Cluster deployment distributed ML and LLM workloads</p> </d-title> <d-byline></d-byline> <d-article> <p>If you’re building large-scale ML systems - distributed training, batch inference, or LLM serving with <strong>vLLM</strong> - combining <strong>Kubernetes + Ray + GKE</strong> gives you a powerful, production-ready stack.<d-footnote>See <a href="https://docs.ray.io/en/latest/cluster/kubernetes/index.html" rel="external nofollow noopener" target="_blank">Ray on Kubernetes</a>, <a href="https://docs.ray.io/en/latest/cluster/getting-started.html" rel="external nofollow noopener" target="_blank">Ray Clusters Overview</a>, and <a href="https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke" rel="external nofollow noopener" target="_blank">Ray on GKE</a> for official documentation.</d-footnote></p> <p>This post walks through:</p> <ul> <li>Architecture overview</li> <li>Setting up GKE (Standard vs Autopilot)</li> <li>Deploy Ray on Google Kubernetes Engine (GKE)</li> <li>Configure GPU-enabled Ray clusters</li> <li>Expose the Ray dashboard securely via Ingress</li> <li>Manage dependencies with <code class="language-plaintext highlighter-rouge">uv</code> </li> <li>Submit distributed jobs from your laptop or CI</li> <li>Prepare your setup for production-grade scaling</li> </ul> <hr> <h2 id="architecture-overview">Architecture Overview</h2> <p>At a high level:</p> <ul> <li> <strong>Google Kubernetes Engine (GKE)</strong> → Infrastructure &amp; orchestration</li> <li> <strong>Ray</strong> → Distributed compute engine</li> <li> <strong>PyTorch</strong> → Model training</li> <li> <strong>vLLM</strong> → High-performance LLM serving</li> </ul> <h3 id="how-it-all-fits-together">How It All Fits Together</h3> <pre><code class="language-mermaid">flowchart TD
    A[User / CI] --&gt;|Submit Job| B(GKE Ingress)
    B --&gt; C[Ray Head Pod]
    C --&gt; D[Ray Workers]
    D --&gt; E[GPU Nodes]
    C --&gt; F[Ray Dashboard 8265]
    D --&gt; G[PyTorch Training]
    D --&gt; H[vLLM Serving]
</code></pre> <hr> <h3 id="what-each-layer-does">What Each Layer Does</h3> <table> <thead> <tr> <th>Layer</th> <th>Responsibility</th> </tr> </thead> <tbody> <tr> <td>GKE</td> <td>Provisions nodes, autoscaling, networking</td> </tr> <tr> <td>KubeRay</td> <td>Manages Ray clusters as CRDs</td> </tr> <tr> <td>Ray</td> <td>Schedules distributed jobs</td> </tr> <tr> <td>vLLM</td> <td>Fast LLM inference</td> </tr> <tr> <td>PyTorch</td> <td>Training &amp; fine-tuning</td> </tr> </tbody> </table> <hr> <h2 id="prepare-your-environment">Prepare Your Environment</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">PROJECT_ID</span><span class="o">=</span>&lt;project_id&gt;
<span class="nb">export </span><span class="nv">REGION</span><span class="o">=</span>us-central1
<span class="nb">export </span><span class="nv">ZONE</span><span class="o">=</span>us-central1-a
<span class="nb">export </span><span class="nv">CLUSTER_NAME</span><span class="o">=</span>ray-cluster
<span class="nb">export </span><span class="nv">POOL_NAME</span><span class="o">=</span>gpu-node-pool
<span class="nb">export </span><span class="nv">NAMESPACE</span><span class="o">=</span>llm

gcloud config <span class="nb">set </span>project <span class="nv">$PROJECT_ID</span>
gcloud config <span class="nb">set </span>billing/quota_project <span class="nv">$PROJECT_ID</span>
gcloud services <span class="nb">enable </span>container.googleapis.com
</code></pre></div></div> <p>Connect to your cluster after creation:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud container clusters get-credentials <span class="nv">$CLUSTER_NAME</span> <span class="nt">--location</span><span class="o">=</span><span class="nv">$REGION</span>
</code></pre></div></div> <hr> <h2 id="create-a-gke-cluster">Create a GKE Cluster</h2> <aside><p><strong>GKE options:</strong> <a href="https://cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/enable-ray-on-gke" rel="external nofollow noopener" target="_blank">Enable Ray on GKE</a> · <a href="https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/gcp-gke-gpu-cluster.html" rel="external nofollow noopener" target="_blank">Start GKE with GPUs for KubeRay</a> (Standard or Autopilot)</p></aside> <p>You have two options. Currently I have only worked on option B.</p> <ol> <li> <p>Option A - Autopilot (Managed Mode)</p> <p>Pros:</p> <ul> <li>Less infrastructure management</li> <li>Ray operator can be enabled directly</li> </ul> <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> gcloud container clusters create-auto <span class="nv">$CLUSTER_NAME</span> <span class="se">\</span>
     <span class="nt">--location</span><span class="o">=</span><span class="nv">$REGION</span> <span class="se">\</span>
     <span class="nt">--release-channel</span><span class="o">=</span>rapid <span class="se">\</span>
     <span class="nt">--enable-ray-operator</span>
</code></pre></div> </div> <p>Autopilot currently has limitations with <code class="language-plaintext highlighter-rouge">--enable-ray-operator</code> in some regions.<d-footnote>Autopilot example: [Deploy Ray Serve Stable Diffusion on GKE](https://docs.cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/tutorials/deploy-ray-serve-stable-diffusion#autopilot). ChatGPT guides: [Deploy RayCluster on GKE](https://chatgpt.com/share/6988d953-7834-800b-a8fd-1387e2bcedc3) · [RayCluster on GKE](https://chatgpt.com/share/6988d9ab-f750-800b-870b-f4b25bf6f281)</d-footnote></p> </li> <li> <p>Option B - Standard Cluster (More Control)</p> <p>Recommended for GPU-heavy ML workloads.<d-footnote>[AI/ML orchestration on GKE](https://cloud.google.com/kubernetes-engine/docs/integrations/ai-infra)</d-footnote></p> <div class="language-bash highlighter-rouge"> <div class="highlight"><pre class="highlight"><code> gcloud container clusters create <span class="nv">$CLUSTER_NAME</span> <span class="se">\</span>
 <span class="nt">--zone</span><span class="o">=</span><span class="nv">$ZONE</span> <span class="se">\</span>
 <span class="nt">--machine-type</span> e2-standard-4 <span class="se">\</span>
 <span class="nt">--num-nodes</span><span class="o">=</span>1 <span class="se">\</span>
 <span class="nt">--enable-autoscaling</span> <span class="se">\</span>
 <span class="nt">--min-nodes</span><span class="o">=</span>0 <span class="nt">--max-nodes</span><span class="o">=</span>2
</code></pre></div> </div> </li> </ol> <hr> <h3 id="add-gpu-node-pool-nvidia-l4-example">Add GPU Node Pool (NVIDIA L4 Example)</h3> <aside><p><strong>GPU resources:</strong> <a href="https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/gpu.html" rel="external nofollow noopener" target="_blank">Using GPUs</a> · <a href="https://docs.cloud.google.com/kubernetes-engine/docs/how-to/serve-llm-l4-ray" rel="external nofollow noopener" target="_blank">Serve an LLM on L4 GPUs with Ray</a></p></aside> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud container node-pools create <span class="nv">$POOL_NAME</span> <span class="se">\</span>
  <span class="nt">--cluster</span><span class="o">=</span><span class="nv">$CLUSTER_NAME</span> <span class="se">\</span>
  <span class="nt">--zone</span><span class="o">=</span><span class="nv">$ZONE</span> <span class="se">\</span>
  <span class="nt">--accelerator</span> <span class="nb">type</span><span class="o">=</span>nvidia-l4,count<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--machine-type</span> g2-standard-4 <span class="se">\</span>
  <span class="nt">--enable-autoscaling</span> <span class="se">\</span>
  <span class="nt">--min-nodes</span><span class="o">=</span>0 <span class="nt">--max-nodes</span><span class="o">=</span>2
</code></pre></div></div> <p>Verify GPU and device plugin:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get nodes <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span><span class="s1">'NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu'</span>
kubectl get pods <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>nvidia-gpu-device-plugin
</code></pre></div></div> <hr> <h2 id="install-kuberay-operator-if-not-using-autopilot">Install KubeRay Operator (If Not Using Autopilot)</h2> <aside><p><strong>Reference:</strong> <a href="https://github.com/ray-project/kuberay/tree/master/helm-chart/kuberay-operator" rel="external nofollow noopener" target="_blank">KubeRay Helm charts</a> · <a href="https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/helm-chart-rbac.html" rel="external nofollow noopener" target="_blank">Helm Chart RBAC</a></p></aside> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update

helm <span class="nb">install </span>kuberay-operator kuberay/kuberay-operator <span class="nt">--version</span> 1.5.1
</code></pre></div></div> <p>Verify:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods
</code></pre></div></div> <p>You should see <code class="language-plaintext highlighter-rouge">kuberay-operator</code> running.</p> <p><strong>Note:</strong> If you created the cluster with <code class="language-plaintext highlighter-rouge">--enable-ray-operator</code> (Autopilot), skip this step—the Ray operator is already installed.</p> <hr> <h3 id="kuberay-kubectl-ray-plugin-autopilot-only">KubeRay kubectl-ray Plugin (Autopilot Only)</h3> <p>For Autopilot clusters with the GKE Ray add-on, you may need the KubeRay kubectl plugin:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Check your KubeRay version (from CRD annotations)</span>
kubectl get crd rayclusters.ray.io <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.metadata.annotations}'</span> <span class="p">;</span> <span class="nb">echo</span>

<span class="c"># Install kubectl-ray (replace v1.4.2 with your version)</span>
curl <span class="nt">-LO</span> https://github.com/ray-project/kuberay/releases/download/v1.4.2/kubectl-ray_v1.4.2_linux_amd64.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> kubectl-ray_v1.4.2_linux_amd64.tar.gz
<span class="nb">cp </span>kubectl-ray ~/.local/bin

kubectl ray version
</code></pre></div></div> <hr> <h2 id="deploy-a-gpu-enabled-raycluster">Deploy a GPU-Enabled RayCluster</h2> <aside><p><strong>Docs:</strong> <a href="https://docs.ray.io/en/latest/cluster/kubernetes/getting-started.html" rel="external nofollow noopener" target="_blank">Getting Started with KubeRay</a> · <a href="https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html" rel="external nofollow noopener" target="_blank">RayCluster Configuration</a></p></aside> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> raycluster-gpu.yaml
</code></pre></div></div> <p>Check status:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get rayclusters
kubectl get pods <span class="nt">--selector</span><span class="o">=</span>ray.io/cluster<span class="o">=</span>raycluster-gpu
</code></pre></div></div> <hr> <h3 id="raycluster-internal-structure">RayCluster Internal Structure</h3> <pre><code class="language-mermaid">flowchart TB
    subgraph GKE Cluster
        H[Ray Head Pod]
        W1[Worker Pod 1]
        W2[Worker Pod 2]
    end

    H --&gt; W1
    H --&gt; W2
    W1 --&gt; GPU1[NVIDIA GPU]
    W2 --&gt; GPU2[NVIDIA GPU]
</code></pre> <hr> <h2 id="access-ray-head-pod">Access Ray Head Pod</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">HEAD_POD</span><span class="o">=</span><span class="si">$(</span>kubectl get pods <span class="se">\</span>
  <span class="nt">--selector</span><span class="o">=</span>ray.io/node-type<span class="o">=</span><span class="nb">head</span> <span class="se">\</span>
  <span class="nt">-o</span> custom-columns<span class="o">=</span>POD:metadata.name <span class="nt">--no-headers</span><span class="si">)</span>

kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$HEAD_POD</span> <span class="nt">--</span> bash
</code></pre></div></div> <hr> <h2 id="expose-ray-dashboard-port-8265-via-gke-ingress">Expose Ray Dashboard (Port 8265) via GKE Ingress</h2> <aside><p><strong>Reference:</strong> <a href="https://docs.ray.io/en/latest/cluster/kubernetes/k8s-ecosystem/ingress.html#gke-ingress-support" rel="external nofollow noopener" target="_blank">GKE Ingress support</a></p></aside> <p>GKE supports <code class="language-plaintext highlighter-rouge">gce</code> (external) and <code class="language-plaintext highlighter-rouge">gce-internal</code> ingress modes. For <code class="language-plaintext highlighter-rouge">gce-internal</code>, you must create a <a href="https://cloud.google.com/load-balancing/docs/proxy-only-subnets#proxy_only_subnet_create" rel="external nofollow noopener" target="_blank">Proxy-Only subnet</a>.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Get Ray head service name, then update ray-dashboard-ingress.yaml</span>
kubectl get svc

kubectl apply <span class="nt">-f</span> ray-dashboard-ingress.yaml
kubectl get ingress
</code></pre></div></div> <p>After a few minutes, GKE assigns an external IP.</p> <p>Visit:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://&lt;EXTERNAL_IP&gt;
</code></pre></div></div> <hr> <h3 id="networking-flow">Networking Flow</h3> <pre><code class="language-mermaid">flowchart LR
    User --&gt; Ingress
    Ingress --&gt; RayHeadService
    RayHeadService --&gt; RayHeadPod
    RayHeadPod --&gt; RayWorkers
</code></pre> <hr> <h2 id="dependency-management-with-uv">Dependency Management with <code class="language-plaintext highlighter-rouge">uv</code> </h2> <p>Ray supports runtime environments.<d-footnote>Ray docs: <a href="https://docs.ray.io/en/latest/ray-core/handling-dependencies.html" rel="external nofollow noopener" target="_blank">Environment Dependencies</a></d-footnote></p> <p><strong>Important:</strong> Local Python version must match the Ray image. For example, <code class="language-plaintext highlighter-rouge">rayproject/ray:2.53.0-gpu</code> uses Python 3.10.19.</p> <hr> <h3 id="use-via-rayinit-inside-ray-pods">Use via ray.init() (Inside Ray Pods)</h3> <p>When running code directly inside the head/worker pod, use <code class="language-plaintext highlighter-rouge">runtime_env</code> with <code class="language-plaintext highlighter-rouge">uv</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv <span class="nb">export</span> <span class="nt">--format</span> requirements.txt <span class="nt">-o</span> requirements.txt
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># runtime_env expects requirements.txt, not pyproject.toml
</span><span class="n">ray</span><span class="p">.</span><span class="nf">init</span><span class="p">(</span><span class="n">runtime_env</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">uv</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">./path/requirements.txt</span><span class="sh">"</span><span class="p">})</span>
</code></pre></div></div> <hr> <h3 id="pattern-a-best-for-iteration-ray-job-submit---uv-run-">Pattern A (Best for Iteration): ray job submit … – uv run …</h3> <p>Keep a repo locally (or on CI) with <code class="language-plaintext highlighter-rouge">pyproject.toml</code>, <code class="language-plaintext highlighter-rouge">uv.lock</code>, and your scripts. Submit from any machine that can reach the Ingress:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv lock

ray job submit <span class="se">\</span>
  <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span> <span class="se">\</span>
  <span class="nt">--no-wait</span> <span class="se">\</span>
  <span class="nt">--working-dir</span> <span class="nb">.</span> <span class="se">\</span>
  <span class="nt">--</span> uv run main.py
</code></pre></div></div> <p>Ray uploads your working directory and installs dependencies. Use <code class="language-plaintext highlighter-rouge">--no-wait</code> for fire-and-forget, then:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ray job logs &lt;job-id&gt; <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span>
ray job status &lt;job-id&gt; <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span>
ray job stop &lt;job-id&gt; <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span>
</code></pre></div></div> <p><strong>Tip:</strong> Set <code class="language-plaintext highlighter-rouge">export RAY_API_SERVER_ADDRESS="http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</code> to avoid passing <code class="language-plaintext highlighter-rouge">--address</code> every time.</p> <hr> <h3 id="remote-working_dir-avoid-local-upload">Remote working_dir (Avoid Local Upload)</h3> <p>Instead of <code class="language-plaintext highlighter-rouge">--working-dir .</code>, use a remote URI so Ray fetches code from GitHub or GCS:</p> <table> <thead> <tr> <th>Source</th> <th>Example</th> </tr> </thead> <tbody> <tr> <td>Public GitHub</td> <td><code class="language-plaintext highlighter-rouge">https://github.com/user/repo/archive/HEAD.zip</code></td> </tr> <tr> <td>Private GitHub</td> <td><code class="language-plaintext highlighter-rouge">https://user:TOKEN@github.com/user/repo/archive/HEAD.zip</code></td> </tr> <tr> <td>GCS</td> <td><code class="language-plaintext highlighter-rouge">gs://bucket/code.zip</code></td> </tr> </tbody> </table> <p>Example with a subdirectory (e.g. <code class="language-plaintext highlighter-rouge">src/</code> in the repo):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ray job submit <span class="se">\</span>
  <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span> <span class="se">\</span>
  <span class="nt">--working-dir</span> <span class="s2">"https://github.com/user/repo/archive/HEAD.zip"</span> <span class="se">\</span>
  <span class="nt">--</span> uv run <span class="nt">--directory</span> src main_src.py
</code></pre></div></div> <hr> <h3 id="pattern-b-best-for-production">Pattern B (Best for Production)</h3> <p>Bake dependencies into the image to avoid per-job installs:</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> rayproject/ray-ml:2.x-gpu</span>
<span class="k">COPY</span><span class="s"> pyproject.toml uv.lock .</span>
<span class="k">RUN </span>uv <span class="nb">sync</span> <span class="nt">--frozen</span>
</code></pre></div></div> <p>Use this image in your RayCluster for both head and workers. Then job submission can ship only code or parameters.</p> <hr> <h3 id="option-3-remote-code-only-no-local-upload">Option 3: Remote Code Only (No Local Upload)</h3> <p>If you want to avoid uploading from your machine entirely:</p> <ol> <li>Zip your repo (single top-level directory) and upload to GCS.</li> <li>Submit with <code class="language-plaintext highlighter-rouge">--runtime-env-json</code> and <code class="language-plaintext highlighter-rouge">working_dir: "gs://bucket/code.zip"</code>:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ray job submit <span class="se">\</span>
  <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP_OR_DNS&gt;:8265"</span> <span class="se">\</span>
  <span class="nt">--runtime-env-json</span><span class="o">=</span><span class="s1">'{"working_dir": "gs://bucket/code.zip"}'</span> <span class="se">\</span>
  <span class="nt">--</span> python main.py
</code></pre></div></div> <hr> <h3 id="production-workflow">Production Workflow</h3> <pre><code class="language-mermaid">flowchart TD
    Dev[Developer] --&gt;|Push Code| GitHub
    GitHub --&gt; CI
    CI --&gt;|Build Image| GCR
    GCR --&gt;|Deploy| GKE
    GKE --&gt; RayCluster
</code></pre> <hr> <h2 id="submitting-jobs-from-local--different-machines-via-ingress">Submitting Jobs from Local / Different Machines (via Ingress)</h2> <aside><p><strong>Job submission:</strong> <a href="https://docs.ray.io/en/latest/cluster/kubernetes/getting-started/rayjob-quick-start.html" rel="external nofollow noopener" target="_blank">RayJob Quickstart</a> · <a href="https://docs.ray.io/en/latest/cluster/running-applications/job-submission/quickstart.html" rel="external nofollow noopener" target="_blank">Ray Jobs CLI Quickstart</a></p></aside> <p>Submit from your laptop, another engineer’s machine, or a CI runner—as long as it has the code and can reach <code class="language-plaintext highlighter-rouge">http://&lt;INGRESS_IP&gt;:8265</code>.</p> <h3 id="1-install-ray-cli">1. Install Ray CLI</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv tool <span class="nb">install</span> <span class="s2">"ray[default]"</span>   <span class="c"># runtime env feature requires ray[default]</span>
</code></pre></div></div> <h3 id="2-submit-options">2. Submit Options</h3> <table> <thead> <tr> <th>Option</th> <th>Use case</th> </tr> </thead> <tbody> <tr> <td><strong>Local dir</strong></td> <td> <code class="language-plaintext highlighter-rouge">--working-dir .</code> — uploads current directory</td> </tr> <tr> <td><strong>Remote GitHub/GCS</strong></td> <td> <code class="language-plaintext highlighter-rouge">--working-dir "https://github.com/user/repo/archive/HEAD.zip"</code> or <code class="language-plaintext highlighter-rouge">gs://bucket/code.zip</code> </td> </tr> <tr> <td><strong>Subdirectory</strong></td> <td>Add <code class="language-plaintext highlighter-rouge">-- uv run --directory src main.py</code> when code lives in a subdir</td> </tr> <tr> <td><strong>No local upload</strong></td> <td><code class="language-plaintext highlighter-rouge">--runtime-env-json='{"working_dir": "gs://bucket/code.zip"}'</code></td> </tr> </tbody> </table> <p>Example (local):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv lock
ray job submit <span class="se">\</span>
  <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP&gt;:8265"</span> <span class="se">\</span>
  <span class="nt">--working-dir</span> <span class="nb">.</span> <span class="se">\</span>
  <span class="nt">--</span> uv run main.py
</code></pre></div></div> <p>Example (remote repo + subdirectory):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ray job submit <span class="se">\</span>
  <span class="nt">--address</span><span class="o">=</span><span class="s2">"http://&lt;INGRESS_IP&gt;:8265"</span> <span class="se">\</span>
  <span class="nt">--working-dir</span> <span class="s2">"https://github.com/user/repo/archive/HEAD.zip"</span> <span class="se">\</span>
  <span class="nt">--</span> uv run <span class="nt">--directory</span> src main.py
</code></pre></div></div> <hr> <h2 id="monitoring--autoscaling">Monitoring &amp; Autoscaling</h2> <p>You should configure:</p> <ul> <li>Ray autoscaling</li> <li>Prometheus + Grafana</li> <li>Cloud Monitoring integration</li> </ul> <p>Ray metrics default port: <strong>8080</strong></p> <hr> <h2 id="when-should-you-use-this-stack">When Should You Use This Stack?</h2> <p>Use Ray + GKE when:</p> <ul> <li>Distributed training</li> <li>Multi-GPU LLM serving</li> <li>Batch inference pipelines</li> <li>Multi-team ML platform</li> <li>CI/CD for ML infra</li> </ul> <p>Avoid if:</p> <ul> <li>Small experiments</li> <li>Single-node workloads</li> <li>No need for autoscaling</li> </ul> <hr> <h2 id="final-thoughts">Final Thoughts</h2> <p>Running <strong>Ray on GKE</strong> gives you:</p> <ul> <li>Kubernetes-native autoscaling</li> <li>GPU scheduling</li> <li>Production-ready LLM serving</li> <li>Distributed PyTorch training</li> <li>Clean job submission model</li> </ul> <p>This stack scales from experimentation → production seamlessly.</p> <aside><p><strong>Video:</strong> <a href="https://www.youtube.com/watch?v=hdx0LHw7epg" rel="external nofollow noopener" target="_blank">Ray on GKE tutorial</a> on YouTube</p></aside> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/deploy-vllm/">Comprehensive Guide to Deploying vLLM on GKE</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/plotly/">a post with plotly.js</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/photo-gallery/">a post with image galleries</a> </li> <br> <br> </d-article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Quan H. Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: February 28, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js" integrity="sha256-1rA678n2xEx7x4cTZ5x4wpUCj6kUMZEZ5cxLSVSFWxw=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?v=38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?v=c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>